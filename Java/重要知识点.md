# 目录

[toc]

# 基础

## 集合

Collection 和 Map，是集合框架的根接口

Collection 又有 Set 、 List 两个子接口

**<font color=red>Map 集合</font>**

key 和 value 都是无序的

存放键值对，每一组数据都有一个关键字 key，在一个 Map 中 key 是唯一的，且不可重复	

​	**HashMap：**

​		线程不安全，效率相对 HashTable 要高一点

​		允许键和值为 null

​		使用数组+双向链表+红黑树实现（java8），当长度达到阈值 8 后，HashMap 由数组和链表实现转换成由红黑树实现

​		默认初始大小为 16，如果指定初始大小，HashMap 会将其扩充为指定值的 2 的幂次方，之后每次扩容为原来的两倍

​		他是按照键的 HashCode 值存储数据，所以根据键获取值的时候回具有很快的访问速度

​	**LinkedHashMap：**

​		与 HashMap 不同的就是它是一个双重链表，存放的元素都是有序的

​	**HashTable：基本上不使用了。如果需要保证线程安全的话，可以使用 `ConcurrentHashMap` **

​		线程安全，内部方法基本上都使用了 synchronized 修饰，效率相对于 HashMap 要低一点

​		key 和 value 都不允许有 null 值

​		默认初始大小为 11，如果指定，就是你指定的值，每次扩容，变为原来的 2n+1

​		Hashtable 比 HashMap 多提供了 elments() 和 contains() 两个方法。

​		elements 作用是返回 HashTable 中 value 的枚举

​		contains 作用是判断 HashTable 中是否包含某个 Value，其实相当于 containsValue

**<font color=red>Set 集合</font>**

所有元素都是无序的，不能有重复元素

​	**HashSet** ：

​		底层其实是 HashMap，用 HashMap 的 Key 存放元素

​		检查重复的机制：

​		添加元素时，会通过 hashCode 检查元素存放的位置，同时，会比较有没有和其他元素的 HashCode 相同，如果没有相同的 HashCode，HashSet 就会认为元素没有重复出现，如果有相同的 HashCode，就会调用 equals 方法进行比对，如果相同，就不会插入成功。

​	**TreeSet：**

​		底层其实是 TreeMap， 使用二叉树实现，元素唯一且有序，需要使用 hashCode 和 equals 方法保证元素唯一性

​	**LinkedHashSet：**

​		需要用额外的链表维护元素的插入顺序，因此在插入时性能比HashSet低，但在迭代访问（遍历）时性能更高。因为插入的时候即要计算hashCode又要维护链表，而遍历的时候只需要按链表来访问元素。

**<font color=red>List 集合</font>**

可以存放重复元素

​	**ArrayList：**

​		线程不安全，底层结构是数组，查询快（可以通过索引快速查到到元素），在集合中间增删速度慢，需要将后面的元素全部后移，需要有一定的预留空间

​	**LinkdList：**

​		线程不安全、底层结构是链表，增删块（只需要修改对应节点），查询慢（需要遍历链表），需要存放元素的父、子节点，内存占用稍大

​	**Vector：**

​		线程安全（方法使用 synchronized 关键字），效率低，底层是数组，查询快

### 为什么hashmap的初始值是2的幂次方

HashMap 的容量是 2 的幂次方是为了优化 HashMap 的哈希函数计算，从而提高 HashMap 的性能和减少哈希碰撞的概率。

HashMap 内部使用一个数组来存储元素，当元素数量达到一定数量时，需要对数组进行扩容。在扩容时，HashMap 会创建一个新的数组，并将旧数组中的元素重新计算哈希值并放入新的数组中。这个过程需要重新计算元素的哈希值和定位元素在数组中的位置，因此是一个比较耗时的操作。

为了减少扩容带来的性能损失，HashMap 的容量必须是 2 的幂次方。这样在计算哈希值时，可以使用位运算代替取模运算，从而提高计算效率。同时，当 HashMap 的容量为 2 的幂次方时，其长度减一的二进制表示中所有位都为 1，这样在计算元素在数组中的位置时，只需要取元素哈希值的低几位即可，这样可以保证元素在数组中的位置分布更加均匀，减少哈希碰撞的概率，提高 HashMap 的性能。

### 集合与数组的区别

数组：长度固定、可以存储基本数据类型和引用数据类型、数组中元素类型相同

集合：长度可变、只能存储引用数据类型、集合中可以存放不同类型的元素

### 数组、集合的转换

<font color=red>**数组转集合：** Arrays.asList();</font>

​	不能转 Set ，因为 Set 不能存放重复元素，数组中有重复元素的话，会出现数据丢失的情况

​	不能使用 add/remove/clear  方法，asList 的返回对象是一个 Arrays 内部类，它没有实现这些方法

**解决方式**：使用 ArrayList 的构造方法，将转换得到的集合再次转换

​	注意：集合只能存放对象，将 int  等基本数据类型的数组转化成集合无效，是空集合

```java
public class Test {
    public static void main(String[] args) {
        String [] a = {"aa","bb"};
        List arrayList = Arrays.asList(a);
//        arrayList.add(8);       //Exception in thread "main" java.lang.UnsupportedOperationException
        a[0] = "cc";
        System.out.println(arrayList.get(0));   //cc
    }
}
```

```java
public static void a() {
    String [] a = {"aa","bb"};
    List list = Arrays.asList(a);
    //将转换得到的 Arrays  内部类再次转换得到 ArrayList
    ArrayList<String> arrayList = new ArrayList<>(list);
    arrayList.add("dd");
    System.out.println(arrayList.get(2));   //dd
}
```

**集合转数组**：<font color=red>list.toArray(array);</font>

​	直接使用 toArray 无参方法，此方法返回值只能是 Object[] 类，如果强转会报错

​	使用 toArray 的有参方法，如果指定的数组长度大于集合的长度，多出来的位置会被赋 null 值，也只能使用 Object[] 接收

```java
public static void main(String[] args) {
    List a = new ArrayList();
    a.add("aa");
    a.add("bb");
    String [] strings = new String[a.size()+1];
    Object[] objects = a.toArray(strings);
    for (Object object : objects) {
        System.out.println(object);   // aa	bb	null	
    }
}
```

<font color=red>**集合转集合：Set 转 List**</font>

​	使用集合的 addAll 方法

```java
public static void c(){
    Set<String> set = new HashSet<>();
    set.add("aa");
    set.add("bb");
    List<String> list = new ArrayList<>();
    list.addAll(set);
    for (String s : list) {
        System.out.println(s);
    }
}
```

## == 和 equals()

对基本数据类型而言：== 比较的就是值

对于引用类型而言：

== 比较的是内存地址

如果 equals 方法没有重写，那么比较的也是内存地址

如果重写 equals 方法，例如：String 的 equals 比较的就是值

通常重写 equals 方法都会重写 hashCode 方法，相同的对象一定要有相同的 hashCode

## instanceof 关键字

用于判断一个对象是否为一个类的实例，当 obj 是 Class 的实例对象、直接或间接子类时，返回 true

```java
System.out.println(obj instanceof Class);
```

<font color=red>注意：obj 必须是引用类型，如果 obj 为 null，则返回 false</font>

## 包装类

### 自动装拆箱

自动装拆箱就是基本数据类型和包装类之间的数据类型转换，<font color=red>jdk1.5 以后才支持</font>

装箱调用 ValueOf() 方法，拆箱调用 xxxValue() 方法

注意：

>jdk1.5 之前必须使用
>
>Integer i = new Integer(10);
>
>jdk1.5 之后可以使用
>
>Integer i = 10;

### 包装类的缓存

支持 -128 ~ 127 之间的整数

在这个范围内的数据，会在证书类第一次使用的时候被初始化出来，以后每次自动装箱都是直接使用

在这个范围之外的数据，每次装拆箱都是 new 一个新的对象

**<font color=red>Float 和 Double 没有使用缓存，Boolean 的两个值全部缓存，Character 的缓存是 0 ~127</font>**

## 重写和重载

重写（`Override`）：子类重写父类的方法

> 子类方法名，形参列表和父类完全一样，
>
> 子类方法的`访问权限`修饰符`不能小于`父类方法
>
> 子类方法的`返回值类型`可以是父类方法返回值类型的`直接或间接子类`
>
> 子类方法抛出的异常范围不能大于父类方法

重载（`Overload`）：同一个类中

>同一个类中，同名方法的形参列表不同（参数个数、参数数据类型、参数位置）
>
>返回值之类的没有要求

## :yellow_heart:Java 中的四种引用

## :yellow_heart:Hash 冲突

## volital 关键字

程序运行时，数据并不会马上存储到内存中，修改数据时，会在 CPU 的缓存行中进行修改，线程结束后再将其推送到内存

有些情况下，当缓存行中的数据被修改后，马上进行了线程的切换，可能会导致缓存行中的数据无法及时推送到内存，出现第一个线程已经修改了数据，但是第二个线程读取到的仍然是旧数据的情况。

volital 关键字的作用就是保证在线程切换前，将 CPU 缓存行中的数据推送到内存中，然后强制使其他处理器上存储该数据的缓存行失效，保证数据的可见性。

## 单例模式

定义：

​	单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例

优点：

​	系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。

缺点：

​	当想实例化一个单例类的时候，必须要记住使用相应的获取对象的方法，而不是使用new，可能会给其他开发人员造成困扰，特别是看不到源码的时候。

特点：

​	单例类只能有一个实例。

​	单例类必须自己创建自己的唯一实例。

​	单例类必须给所有其他对象提供这一实例。

​	单例模式保证了全局对象的唯一性，比如系统启动读取配置文件就需要单例保证配置的一致性

单例模式的使用场景：

​	需要频繁的进行创建和销毁的对象；

​	创建对象时耗时过多或耗费资源过多，但又经常用到的对象；

​	工具类对象；

​	频繁访问数据库或文件的对象。

### <font color=red>常用实现方式：</font>

```java
public class test02 {
    public static void main(String[] args) {
        Singleton1 singleton1 = Singleton1.getSingleton();
        Singleton1 singleton2 = Singleton1.getSingleton();
        System.out.println(singleton1==singleton2);     // true

        Singlenton2 singleton2a = Singlenton2.getSingleton2();
        Singlenton2 singleton2b = Singlenton2.getSingleton2();
        System.out.println(singleton2a==singleton2b);       // true

        Singlenton3 singlenton3a = Singlenton3.getSinglenton3();
        Singlenton3 singlenton3b = Singlenton3.getSinglenton3();
        System.out.println(singlenton3a==singlenton3b);		// true
    }
}


/**
 * 饿汉
 */
class Singleton1{
    public static final Singleton1 singleton1 = new Singleton1();

    Singleton1(){}

    public static Singleton1 getSingleton(){
        return singleton1;
    }
}

/**
 * 双重检查锁
 */
class Singlenton2{

    public static volatile Singlenton2 singleton2;

    Singlenton2(){}

    public static Singlenton2 getSingleton2(){
        if (singleton2 == null){
            synchronized (Singlenton2.class){
                if (singleton2 == null){
                    singleton2 = new Singlenton2();
                }
            }
        }
        return singleton2;
    }
}

/**
 * 内部类
 */
class Singlenton3{

    Singlenton3() {}

    public static class getSinglenton{
        public static final Singlenton3 singlenton3 = new Singlenton3();
    }

    public static Singlenton3 getSinglenton3(){
        return getSinglenton.singlenton3;
    }
}
```

#### ThreadLocal 实现单例

ThreadLocal 实现的单例并不能保证全局都只有一个实例，他只能保证在单线程的情况下只产生一个实例，**<font color=red>多线程情况下得到的实例并不是同一个</font>**

```java
package designPatterns;

public class Singleton {
    public static void main(String[] args) {
        Singleton1 instance = Singleton1.getInstance();
        Singleton1 instance1 = Singleton1.getInstance();
        System.out.println(instance);
        System.out.println(instance1);
        System.out.println(instance1 == instance);	// true

        new Thread(() -> {
            Singleton1 instance2 = Singleton1.getInstance();
            System.out.println(instance2);	// designPatterns.Singleton1@168193e5
        }).start();

        new  Thread(()->{
            Singleton1 instance3 = Singleton1.getInstance();
            System.out.println(instance3);	// designPatterns.Singleton1@4025fef1
        }).start();
    }

}

/**
 * ThreadLocal 实现单例模式
 */
class Singleton1 {

    private Singleton1() {
    }

    private static final ThreadLocal<Singleton1> threadLocal = new ThreadLocal<Singleton1>() {
        @Override
        protected Singleton1 initialValue() {
            return new Singleton1();
        }
    };

    public static Singleton1 getInstance() {
        return threadLocal.get();
    }
}

```

### 反射和反序列化如何保证单例：

解决序列化破坏单例问题：添加 readResolve 方法，返回当前对象

解决反射破坏单例问题：私有化构造方法，禁止使用反射创建实例

```java
class Singlenton3{

    privte Singlenton3() {
        if(getSinglenton.singlenton3 != null){
            throw new RuntimeException("不允许创建多个实例");
        }
    }

    public static class getSinglenton{
        public static final Singlenton3 singlenton3 = new Singlenton3();
    }

    public static Singlenton3 getSinglenton3(){
        return getSinglenton.singlenton3;
    }
    
    public Singlenton3 readResolve(){
        return getSinglenton.singlenton3;
    }
}
```

## ThreadLocal

ThreadLocal 叫做线程局部变量，在并发编程的时候，不同的用户使用同一个全局变量是线程不安全的，一个用户修改这个数据会造成其他用户的数据也被更改

使用 ThreadLocal 就可以很好的解决这个问题

每一个线程都维护了一个 `ThreadLocalMap`，属性名叫做 `threadLocals`

```java
public class Thread implements Runnable {
	···
    /* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ···
```

我们在调用 get 或者 set 方法时，会先获取当前线程，然后获取到当前线程的 `threadLocals` 进行操作，其他线程操作时，由于线程不同，所以操作的数据也不相同，源码如下：

```java
public class ThreadLocal<T> {
    
	public T get() {
        // 获取当前线程
        Thread t = Thread.currentThread();
        // 得到当前线程的 threadLocals
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();
    }
    
    public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
}
```

## ConcurrentHashMap

java7 中的 ConcurrentHashMap 采用分段锁的机制来实现并发的更新操作，底层是链表+数组的存储结构

它包含两个核心内部类，Segment 和 HashEntry。

> Segment 继承 ReentrantLock 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶
>
> HashEntry 用来封装映射表的键值对；
>
> 每个桶是由若干个 HashEntry 对象链接起来的链表。
>
> 一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组

1.8 的实现已经抛弃了 Segment 分段锁机制，利用 CAS + Synchronized 来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构。整个看起来就像是优化过且线程安全的HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本。

## 多线程

### 线程的四种实现方式

继承 Thread 类、实现 Runnable 接口、实现 Callable 接口（可以有返回值）、线程池

### 怎样停止一个运行的线程

推荐：使用自定义标记

### 线程池

#### 线程池的优点

减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。

运用线程池能有效的控制线程最大并发数，可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。

对线程进行一些简单的管理，比如：延时执行、定时循环执行的策略等，运用线程池都能进行很好的实现

#### 线程池的创建

线程池的撞见有两大类方法，一类是通过 Executors 工厂类提供的方法创建，该类提供了 5 种不同的线程池可供使用。另一类是通过 ThreadPoolExecutor 类进行自定义创建。

**<font color=red>《阿里巴巴java开发手册》中强制规定不要使用 Executors 类提供的四种创建线程的方式，而是使用 ThreadPoolExecutor 自定义创建线程，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。</font>**

<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220704163705527.png" style="border: 2px solid #ddd;">

#### 通过 Executors 工厂类提供的方法创建线程池

**newCachedThreadPool():**创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程。

​	用来处理**大量短时间的**工作任务，具有几个鲜明特点：

​		初始线程池没有线程，而线程不足会不断新建线程。

​		它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；

​		如果线程闲置的时间超过**60** 秒，则被终止并移出缓存；

​		长时间闲置时，这种线程池，不会消耗什么资源。其内部使用 SynchronousQueue 作为工作队列。

**newFixedThreadPool(int nThreads)：**创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待。

​	重用指定数目（nThreads）的线程，其背后使用的是**无界**的工作队列，任何时候最多有 nThreads 个工作线程是活动的。

​	这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；

​	如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目 nThreads。

**newSingleThreadExecutor()：**创建一个单线程的线程池，可保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

​	它的特点在于工作线程数目被限制为 1，操作一个**无界**的工作队列，所以它保证了所有任务的都是被顺序执行

​	最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。

**newSingleThreadScheduledExecutor() 和 newScheduledThreadPool(int corePoolSize)：**创建一个周期性的线程池，支持定时及周期性执行任务。

​	创建的是个 ScheduledExecutorService，可以进行**定时或周期性**的工作调度，区别在于**单一工作线程还是多个工作**线程。

**newWorkStealingPool(int parallelism)：**

​	这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法

​	其内部会构建 ForkJoinPool，利用Work-Stealing 算法，并行地处理任务

​	不保证处理顺序。

#### 通过ThreadPoolExecutor类自定义线程池

```java
ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
```

最大支持 7 个参数：

```java
public ThreadPoolExecutor(int corePoolSize,		// 核心线程数，线程池中始终存活的线程数。
                          int maximumPoolSize,	// 最大线程数，线程池中允许的最大线程数。
                          long keepAliveTime,	//  存活时间，线程没有任务执行时最多保持多久时间会终止。
                          TimeUnit unit,		// 单位，参数keepAliveTime的时间单位，7种可选。
                          
                          //  一个阻塞队列，用来存储等待执行的任务，均为线程安全，7种可选
                          // 较常用的是LinkedBlockingQueue和Synchronous
                          BlockingQueue<Runnable> workQueue,  
                          ThreadFactory threadFactory,		// 线程工厂，主要用来创建线程，默及正常优先级、非守护线程。
                          RejectedExecutionHandler handler	// 拒绝策略，拒绝处理任务时的策略，4种可选，默认为AbortPolicy。
                         ) {···}
```

**unit 参数可选项：**

| 参数                  | 描述 |
| --------------------- | ---- |
| TimeUnit.DAYS         | 天   |
| TimeUnit.HOURS        | 小时 |
| TimeUnit.MINUTES      | 分   |
| TimeUnit.SECONDS      | 秒   |
| TimeUnit.MILLISECONDS | 毫秒 |
| TimeUnit.MICROSECONDS | 微妙 |
| TimeUnit.NANOSECONDS  | 纳秒 |

**workQueue 参数可选项：**

| 参数                  | 描述                                                         |
| --------------------- | ------------------------------------------------------------ |
| ArrayBlockingQueue    | 一个由数组结构组成的有界阻塞队列。                           |
| LinkedBlockingQueue   | 一个由链表结构组成的有界阻塞队列。                           |
| SynchronousQueue      | 一个不存储元素的阻塞队列，即直接提交给线程不保持它们。       |
| PriorityBlockingQueue | 一个支持优先级排序的无界阻塞队列。                           |
| DelayQueue            | 一个使用优先级队列实现的无界阻塞队列，只有在延迟期满时才能从中提取元素。 |
| LinkedTransferQueue   | 一个由链表结构组成的无界阻塞队列。与SynchronousQueue类似，还含有非阻塞方法。 |
| LinkedBlockingDeque   | 一个由链表结构组成的双向阻塞队列。                           |

**handler 参数可选项：**

| 参数                | 描述                                                      |
| ------------------- | --------------------------------------------------------- |
| AbortPolicy         | 拒绝并抛出异常。                                          |
| CallerRunsPolicy    | 重试提交当前的任务，即再次调用运行该任务的execute()方法。 |
| DiscardOldestPolicy | 抛弃队列头部（最旧）的一个任务，并执行当前任务。          |
| DiscardPolicy       | 抛弃当前任务。                                            |

## double 和 float 不能用来计算

duoble 和float 在进行运算时是将数据转换成二进制后进行计算、然后转换成十进制数进行展示的，在这个过程中，会出现进度丢失的问题

解决方法：先将 double 转为字符串，然后将字符串转为 BigDecimal 后进行计算

```java
public class Test {
    public static void main(String[] args) {
        double i = 3;
        double j = 2.6;
        double a = i - j;
        System.out.println(a);		//0.3999999999999999
        BigDecimal i1 = new BigDecimal(String.valueOf(i));
        BigDecimal j1 = new BigDecimal(String.valueOf(j));
        BigDecimal add = i1.remainder(j1);
        System.out.println(add);	//0.4
    }
}
```

## 锁 

**可重入：**当一个线程执行到某个synchronized方法时，比如说method1

而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。

**可中断：**如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。

**公平锁：**公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。

非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。但其吞吐量比公平锁大

### lock 和 synchronized 

synchronized 是一个关键字，能够自动的释放锁，如果一个已经获得锁的线程阻塞，其他的线程就会一直等待。他适合少量并发的情况，如果并发量很大，他的性能会急速下降。但是 jdk6 引入了偏向锁和轻量级锁，使得 synchronized 和 ReentrantLock 相差无几，甚至在某些场景下其性能更是会超过 ReentrantLock 。可重入、不可中断、非公平

lock 是一个接口，通常使用其实现类 ReentrantLock，他不能够自动释放锁，需要在 finally 代码块中使用 unlock 对所进行释放，在并发量很大的情况下，他的性能也可以很稳定。可重入、可中断、可公平
lock 锁默认是非公平的，但可以设置为公平锁

### jdk 对 synchronized 关键字的优化

参考：https://blog.csdn.net/F_Hello_World/article/details/104666734

jdk 对 synchronized 关键字的优化主要是在 jdk1.6 的时候，jdk1.6 之前，synchronized 是一个重量级的悲观锁，每次使用锁都需要直接向操作系统获取锁，所以效率低、占用资源。jdk1.6 之后加入了锁升级的功能。

<font color=red>锁升级其实是指，随着多线程并发加锁的程度提高，而相应的对锁的状态的升级，这个升级是不可逆的。</font>可以分为：无锁——> 偏向锁 ——> 轻量级锁 ——> 重量级锁；

任何一个 java 对象都看看呀看做是一个被加锁的对象，因为 java 对象找内存中存储的结构如下：

<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/2020030611091779.png" alt="img" style="zoom: 50%;" />

在对象头中主要存储的主要是一些运行时的数据，如下所示：

| 长度     | 内容                   | 说明                        |
| :------- | :--------------------- | :-------------------------- |
| 32/64bit | Mark Work              | hashCode,GC分代年龄，锁信息 |
| 32/64bit | Class Metadata Address | 指向对象类型数据的指针      |
| 32/64bit | Array Length           | 数组的长度(当对象为数组时)  |

Mark Work 中存储着该对象作为锁时的一些信息，如下所示是 Mark Work 中在 64 位系统中详细信息：

![image-20220712141405846](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220712141405846.png)

#### 偏向锁：

偏向锁和无锁的标志位在 Mark Work 中的标志位都为 `01`,这说明每一个对象创建出来都可能是偏向锁，具体是否偏向要看具体实现。

偏向锁即锁偏向第一次访问他的线程，当一个线程进入被 synchronized 修饰的代码块时，就会根据 CAS 的操作，将线程的 id 插入 Mark Work 中对应的区域（56bit），同时将是否偏向锁的标识改为 `1`。

后续如果没有其他线程进来访问这个锁或者没有发生锁的竞争，那么第一个线程再次访问时，会判断当前线程 id 与 Mark Work 中保存的是否一致，如果一致就可以直接访问。

如果一个新的线程来请求该锁，它会判断之前拥有这个锁的线程是否存在。如果不存在，或者存在但没拥有该锁的状态，就进行重置该偏向锁并重新进行上锁过程。若仍然存在，<font color=red>此时该偏向锁就会升级为*轻量级锁*。</font>(<font color=red>多个线程交替加锁，并没有出现同时竞争这个锁的情况，此时该偏向锁就会升级为轻量级锁。</font>在这个升级的过程中就会涉及到锁撤销的过程，锁撤销的过程也是满复杂的，资源的消耗也挺大的。所以如果我们的应用中大量都是存在多线程锁竞争的关系，那么不断的进行锁升级，其实是一个没必要的事情，此时我们可以在启动的时候设置 `-XX:-UseBiasedLocking = false`，即该应用就不存在偏向锁了。)

#### 轻量级锁：

当一个锁从偏向锁升级为轻量级锁时，那么对应的 Mark Work 中的数据格式也会发生变更：

1. <font color=red> 锁的标志位切换为 `00`</font>
2. <font color=red>在当前线程栈创建锁记录 LockRecord</font>
3. 将锁对象的对象头中的 Mark Word 复制到线程的刚刚创建的锁记录中
4. 将锁记录中的 Owner 指针指向锁对象
5. <font color=red>将 Mark Work 中 62bit 的空间存储指向获取锁线程的锁记录 LockRecord</font>

轻量级锁中一旦出现竞争，就会膨胀为重量级锁

#### 重量级锁

锁的标志位切换为 `10`

膨胀为重量级锁后，没有抢到 cpu 的线程并不会直接阻塞，而是先自旋

> 自旋锁：（参考：https://www.cnblogs.com/yescode/p/14474104.html）
>
> 已经获取到锁的资源执行同步代码块中的代码，没获取到锁的线程原地循环等待，而不是直接阻塞该线程。
>
> 在得到锁资源的线程执行完成后，这些等待的资源就会开启下一次竞争
>
> 在线程自旋的过程中这些线程是存活的，只不过cpu是一直空转的，就是相对于执行一个没有结束的for循环(在java源码中有关于CAS的操作大都是通过for进行自旋)。如果说自旋次数过多就会导致cpu资源的浪费，所以对于自旋的次数，java对其做了规定，默认每个线程最多执行10次(该值)。所以从这上面看来如果要求自旋锁能达到最优状态，最好是同步代码块中的代码执行时间短，并且只存在少量的锁竞争关系。

> 自适应自旋锁：该锁在jdk1.6的时候被引入
>
> 线程的自旋次数不再是固定值了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。
>
> 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。
>
> 如果对于某个锁，自旋很少成功获得过，为了避免浪费处理器资源，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞

随着线程不断增多，自旋了一定时间或者次数也没能获取到锁，为了减少 cpu 资源的消耗，轻量级锁就会直接升级为重量级锁，获取到重量级锁的线程执行完成后，在解锁的时候回唤醒之前阻塞的线程，让他们争抢 cpu 时间片

## 什么是 CAS

参考一下：https://blog.csdn.net/lwang_IT/article/details/121638089

`java.util.concurrent` 包借助 `CAS` 实现了区别于 `synchronized` 同步锁的一种乐观锁

是一个线程安全问题的乐观锁解决方案，通过循环判断，比较预期原值是否变动，如果没有改变，就表示没有被操作过，这时，将新值放入内存对象。

如果预期原值被修改，则获取被修改的值为新的预期原值，并再次循环；

> CAS 有三个操作数----**内存对象（V）、预期原值（A）、新值（B）**。
>
> CAS 原理就是对v对象进行赋值时，先判断原来的值是否为 A，如果为 A，就把新值 B 赋值到 V 对象上面，如果原来的值不是 A（代表 V 的值放生了变化），就不赋新值。

## CAS 的缺点

### ABA问题:

因为 CAS 需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但是实际上却变化了。

JDK 提供了两个类 `AtomicStampedReference`、`AtomicMarkableReference` 来解决 ABA 问题。

### 只能保证一个共享变量的原子操作

一个比较简单的规避方法为：把多个共享变量合并成一个共享变量来操作。 JDK 提供了 `AtomicReference` 类来保证引用对象之间的原子性，可以把多个变量放在一个 `AtomicReference` 实例后再进行 CAS 操作。比如有两个共享变量 i＝1、j=2，可以将二者合并成一个对象，然后用 CAS 来操作该合并对象的 `AtomicReference` 引用。

### 循环时间长开销大

高并发下N多线程同时去操作一个变量，会造成大量线程CAS失败，然后处于自旋状态，导致严重浪费CPU资源，降低了并发性。

解决 CAS 恶性空自旋的较为常见的方案为：

- 分散操作热点，使用 `LongAdder` 替代基础原子类 `AtomicLong`。
- 使用队列削峰，将发生 CAS 争用的线程加入一个队列中排队，降低 CAS 争用的激烈程度。JUC 中非常重要的基础类 AQS（抽象队列同步器）就是这么做的。

## 原子类 Atomic

Java1.5 的 `Atomic` 包名为 `java.util.concurrent.atomic`。这个包提供了一系列原子类。这些类可以保证多线程环境下，当某个线程在执行 `atomic` 的方法时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择一个线程执行。Atomic 类在软件层面上是非阻塞的，它的原子性其实是在硬件层面上借助相关的指令来保证的。

Atomic包中的类可以分成4组：

<table>
  <tbody><tr>
    <th>类型</th>
    <th>具体实现类</th>
    <th>描述</th>
  </tr>
    <tr>
    <td rowspan="3">基本数据类型</td>
    <td>AtomicInteger</td>
    <td>原子更新Integer类型</td>
  </tr>
  <tr>
    <td>AtomicBoolean</td>
    <td>原子更新boolean类型</td>
  </tr>
<tr>
    <td>AtomicLong</td>
    <td>原子更新long类型</td>
  </tr>
    <tr>
    <td rowspan="3">数组类型</td>
    <td>AtomicIntegerArray</td>
    <td>原子更新Integer数组类型</td>
  </tr>
  <tr>
    <td>AtomicLongArray</td>
    <td>原子更新long数组类型</td>
  </tr>
<tr>
    <td>AtomicReferenceArray</td>
    <td>原子更新对象数组类型</td>
  </tr>    <tr>
    <td rowspan="3">引用类型</td>
    <td>AtomicReference</td>
    <td>原子更新对象</td>
  </tr>
  <tr>
    <td>AtomicStampedReference</td>
    <td>原子更新对象，解决ABA问题</td>
  </tr>
<tr>
    <td>AtomicMarkableReference</td>
    <td>原子更新对象，解决ABA问题</td>
  </tr>    <tr>
    <td rowspan="3">更新字段类型</td>
    <td>AtomicIntegerFieldUpdater</td>
    <td>原子更新已存在的volatile修饰的Integer类型，使用反射实现</td>
  </tr>
  <tr>
    <td>AtomicLongFieldUpdater</td>
    <td>原子更新已存在的volatile修饰的long类型，使用反射实现</td>
  </tr>
<tr>
    <td>AtomicReferenceFieldUpdater</td>
    <td>原子更新已存在的volatile修饰的对象，使用反射实现</td>
  </tr>
</tbody></table>

## 防止空指针异常

1. 在字符串进行比较时，有值的放前面，不确定的方后面

```java
System.out.println("a".equals(a));
```

2. 在创建对象时，最好初始化一个默认值 
2. 返回集合时，如果这个集合为 null，可以创建一个空集合返回

```java
public List getList(){
    List<String > list = null;
    return list == null ? new ArrayList<String>() : list;
}
```

4. 使用 Optional 对象，示例：

```java
public static void main(String[] args) {

    String a = null;
    Optional<String> a1 = Optional.ofNullable(a);
    // 判断是否有值，有就返回 true
    boolean present = a1.isPresent();
    System.out.println(present);
    // 判断是否有值，有就执行后面的表达式，a 就是值
    a1.ifPresent( u -> System.out.println(u));
    // 判断是否有值，有就执行后面的表达式，必须返回一个 Optional
    Optional<Object> o = a1.flatMap(u -> {
        System.out.println(u);
        return Optional.ofNullable(u);
    });
    // 判断是否有值，没有就返回默认值（参数中的）
    Object aFalse = o.orElse("false");
    System.out.println(aFalse);

}
```

## 反射

Java的反射机制是在编译并不确定是哪个类被加载了，而是在程序运行的时候才加载、探知、自审。使用在编译期并不知道的类

### 三种获取对象的方式：

```java
@Test
public void testB(){
    //方式一：
    person a = new person();
    Class aClass = a.getClass();

    //方式二：
    Class<person> personClass = person.class;

    //方式三：
    try {
        Class aClass1 = Class.forName("com.zym.pojo.person");
    } catch (ClassNotFoundException e) {
        e.printStackTrace();
    }
}
```

### 获取属性的三种方式：
field（最快）

```java
Field[] declaredFields = aClass.getDeclaredFields();
for (Field declaredField : declaredFields) {
    declaredField.setAccessible(true);
    System.out.println(declaredField.getName()+" = "+declaredField.get(a));
}
```

BeanUtils（最慢，需要引入jar包）
Method

```java
Method getAge = aClass.getDeclaredMethod("getAge");
System.out.println(getAge.invoke(a, null));
```

反射执行目标方法：

```java
Method method = aClass.getDeclaredMethod("test");
method.setAccessible(true);
method.invoke(a, null);
```

## 泛型

### 泛型类型擦除

java 的泛型是伪泛型，在编译期间，所有的泛型信息都会被擦除掉，生成的字节码文件中是不包含泛型信息的，使用泛型时加上的类型参数，在编译的时候会被去掉，这个过程被称为泛型的类型擦除

被擦除的类型会变成原始类型

例如：ArayList\<T\> 会变成 ArrayList （也就是 ArrayList\<Object\>）

ArrayList\<Intger\> 在类型擦除后其实可以通过反射存储字符串

但是，如果在类中声明变量时写的：

```java
public class Pair<T extends Comparable> {}
```

那么他的原始类型就是 Comparable 

### 类型擦除引起的问题：
#### <font color=red>先检查，后编译</font>

java针对泛型的检查是在编译之前完成的（先检查，后编译，编译的时候回进行类型擦除），所以我们无法添加不同的类型的数据

下面的第一种情况是相当于正常的泛型引用，第二种相当于没有使用泛型，**真正设计类型检查的是它的引用（前面）**，因为我们是使用它来引用 list1 进行方法的调用的

```xml
ArrayList<String> list1 = new ArrayList(); //第一种 情况
ArrayList list2 = new ArrayList<String>(); //第二种 情况
```

#### <font color=red>自动类型转换</font>

因为类型转换，所有的泛型类型最后都会被替换为原始类型，那么，我们获取数据时为什么不需要进行强制类型转换？

例如：在 ArrayList 的 get 方法中，可以看到，return 之前会根据泛型类型进行强制转换，所以不用我们自己进行转换

```java
public E get(int index) {  

    RangeCheck(index);  

    return (E) elementData[index];  

}
```

#### <font color=red>类型擦除与多态的冲突</font>

按理说，下面的 c 继承 P，P 在编译后类型擦除，变成了 Object，子类方法的返回值跟参数类型是Integer，那么子类 c 为什么能重写父类的方法（而不是重载）？

因为 JVM 在编译时使用了**桥方法**，创建了两个桥方法调用我们的方法，实现了重写

解决了类型查出和多态的冲突

```java
public class Test01 {
    public static void main(String[] args) {
        c c1 = new c();
        c1.setValue(9);
        Integer value = c1.getValue();
        System.out.println(value);
    }
}

class c extends P<Integer>{
    public Integer a;
    @Override
    public Integer getValue() {
        return super.getValue();
    }
    @Override
    public void setValue(Integer value) {
        super.setValue(value);
    }
}


class P <T> {
    public T value;
    public T getValue() {
        return value;
    }
    public void setValue(T value) {
        this.value = value;
    }
}
```

#### <font color=red>泛型的类型不能是基本数据类型</font>

因为泛型类型擦除后，会转为 Object 类型，Object 不能存储基本数据类型

### 静态方法不能使用泛型类声明的泛型类型

```java
public class Test2<T> {    
    public static T one;   //编译错误    
    public static  T show(T one){ //编译错误    
        return null;    
    }    
}
```

上面编译错误，但是下面编译正确

```java
public class Test2<T> {     
    public static <T>T show(T one){
        return null;    
    }    
}
```

因为在下面这个 show 方法中，T 所指的类型并不是类声明时的数据类型，而是方法中 T 前面声明的数据类型、

## 多态

多态是同一个行为具有多个不同表现形式或形态的能力。

多态的三个必要条件：

​	要有继承；

​	要有重写；

​	父类引用指向子类对象：FU a = new ZI();

可以通过<font color=red>**重载、接口、继承**</font>这三种方式实现多态

```java
多态的方法调用，有一个类 A，有一个类 B 继承 A；
创建实例： A a = new B();
调用方法： a.xxx(xxx);
他会先找 A 中有没有这个方法，如果有，再看 B 中有没有这个方法的重写，
	有就调用 B 中的方法，没有就调用 A 中的方法。
在找 A 中的方法时，没有找到，会将参数向上转型，直到 A 中有匹配的类型，
	然后按照流程找 B 中有没有重写。有就调用 B 中的方法，没有就调用 A 中的方法。
```

向上转型：父类的引用指向子类对象，例如 FU a = new ZI();

   	 一般可以自动向上转型，

向下转型：向下转型需要强制转换，强制类型转换之前，先使用 instanceof 判断前面的对象是否为后面的类或子类的实例，如果是则返回 true，可以往下执行，不是就会返回 false 跳出判断，全部示例如下：

```java
public class Test02 {
    public static void main(String[] args) {
        A a = new B();
        B b = null;
        if ( a instanceof B){
            b = (B)a;
        }
        b.show(2);
    }
}

class A {
    public void show(A a){ System.out.println("A ----- A"); }
    public void show(B b){ System.out.println("A ------ B"); }
}

class B extends A{
    public void show(A a){ System.out.println("B ------ A"); }
    public void show(C c){ System.out.println("B ------ C"); }
    public void show(Integer a){ System.out.println("B------I");}
}

class C extends B {}
class D extends B {}
```

## servlet单例还是多例

默认是单例的

但是，如果项目部署分布式环境中，Servlet 实现了 SingleThreadModel（已经废弃，不建议使用） 接口，一个 servlet 在 web.xml 中配置了多次，这三种情况下 servlet 就是多实例的

实现 SingleThreadModel 最多会创建 20 个实例，具体多少不清楚

**<font color=red>问题：单例模式下，发送两个请求，在第一个请求还未响应的情况下发送第二个请求，第二个请求的响应可能会覆盖第一个请求的响应（用户 A 先请求，用户 B 后请求，A 可能会获取到 B 的响应数据</font>**

<font color=red>**解决：**</font>

​	**<font color=red>继承 SingleThreadModel（此接口已经废弃） 接口，让其创建多个实例，相当于单线程模式，严重影响性能</font>**

​	**<font color=red>尽量将全局变量改为局部变量使用</font>**

​	**<font color=red>全局变量时增加同步锁（synchronized 或 lock）</font>**

## 序列化

三种方式：传统的对象输入输出流，Hession，JSON

序列化通常会作为网络传输对象，其中可能包含敏感数据，容易被黑客攻击。

​	我们可以在字段上加上 `transient` 关键字，不让此信息序列化成二进制流。

​	或者使用对称与非对称加密方式独立传输，再使用某个方法把属性还原到对象中。

​	应用开发者对序列化要有一定的安全防范意识，对传入数据的内容进行校验或权限控制，及时更新安全漏洞，避免受到攻击。

### 传统方式：

使用 ObjectOutputStream 和 ObjectInputStream 实现对象的序列化

被序列化的对象必须实现 `Serializable` 接口，`Serializable` 没有任何方法，只起到标识作用

```
实现 Serializable 接口的类建议设置 serialVersionUID 字段值
如果不设置，那么每次运行时，编译器会根据类的内部实现， 包括类名、接口名、方法和属性等来自动生成 serialVersionUID。如果类的源代码有修改，那么重新编译后 serialVersionUID 的取值可能会发生变化。
因此实现 Serializable 接口的类一定要显式地定义 serialVersionUID 属性值。修改类时需要根据兼容性决定是否修改serialVersionUID 值
	如果是兼容升级，请不要修改 serialVersionUID 字段， 避免反序列化失败。
	如果是不兼容升级，需要修改 serialVersionUID 值，避免反序列化混乱。
```

### JSON

JSON 是一种轻量级的数据交换格式，JSON 序列化就是将数据对象转换成 JSON 字符串，JSON 在序列化过程中抛弃了数据的类型信息，所以需要提供数据类型信息才能准确的反序列化

可读性好，方便调试

### 使用 Hession 进行序列化：

支持动态类型、跨语言、基于对象传输的网络协议，效率高

特性：

​	自描述序列化类型。不依赖外部描述文件或接口定义， 用一个字节表示常用基础类型， 极大缩短二进制流。

​	语言无关，支持脚本语言。

​	协议简单，比 Java 原生序列化高效。

相比 Hessian 1.0, Hessian 2.0 中增加了压缩编码，其序列化二进制流大小是 Java 序列化的 50%，序列化耗时是 Java 序列化的 30% ，反序列化耗时是 Java 反序列化的 20% 。

缺点：

Hessian 会把复杂对象所有属性存储在一个 Map 申进行序列化。所以在父类、子类存在同名成员变量的情况下， Hessian 序列化时，先序列化子类，然后序列化父类，因此反序列化结果会导致子类同名成员变量被父类的值覆盖。

#### 示例

需要引入 hession 依赖

```xml
<dependency>
    <groupId>com.caucho</groupId>
    <artifactId>hessian</artifactId>
    <version>3.1.5</version>
</dependency>
```

代码：

```java
public class TestString{

    public static void main(String[] args) throws IOException {

        HessianOutput out = new HessianOutput(new FileOutputStream("E://testHessian.txt"));
        User user = new User();
        user.setAge(18);
        user.setName("张三");
        out.writeObject(user);

        HessianInput in = new HessianInput(new FileInputStream("E://testHessian.txt"));
        Object o = in.readObject();
        if (o instanceof User) {
            User user1 = (User) o;
            System.out.println(user1);
        }
    }
}

class User implements Serializable{
    public static final long serialVersionUID = UUID.nameUUIDFromBytes("123".getBytes()).getMostSignificantBits();
    private String name;
    private int age;

    @Override
    public String toString() {
        return "User{" +
                "name='" + name + '\'' +
                ", age=" + age +
                '}';
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }
}
```

## 有状态和无状态

### 对象的有状态和无状态

**有状态对象：**就是<font color=red>普通 java 类</font>，带有属性，<font color=red>并且属性是可以修改的</font>，也就是这种对象是可以进行数据存储的。

<font color=red>注意：</font>属性一定要可以修改，那么这个类的实例就是有状态。也就是你拿到这个对象，有可能被人修改过，也就是可能发生过状态变化。

**无状态对象：**就是<font color=red>对象中的属性不会被更改</font>，不管谁拿过去用过之后没有任何变化 。一般而言，spring 中使用 @service 注解标注的类所产生的对象就是无状态的。

<font color=red>注意：</font>spring 中无状态的对象才能被设置为单例模式 singleton

### 有状态的服务设计和无状态的服务设计

**有状态：**即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，最典型的就是 http 中的 session

- 服务端保存大量数据，增加服务端压力
- 服务端需要保存用户状态，无法进行水平扩展
- 客户端请求依赖服务端，多次请求必须访问同一台服务器
- 例如 用户登录后将用户信息保存在 session 中，由于 session 信息是存储到服务器上的，如果是分布式应用，在访问其他服务器上的服务时就无法获取到之前登录的服务器上存储的用户信息

**无状态：**客户端的请求每次都必须具备足够的信息，服务端通过这些信息就可以识别客户端身份。

- 客户端请求不依赖服务端的信息，任何多次请求不需要访问到同一台服务器
- 服务端的集群和状态对客户端透明 ，也就是说服务端可以任意的迁移或者伸缩
- 最典型的就是 cookie ，例如 jwt 单点登录，用户登录成功后将 token 信息存放到 cookie 中。不管是访问哪个服务器的服务，都可以通过 cookie 获取到用户信息

## 深拷贝和浅拷贝

### 浅拷贝

浅拷贝仅将一个对象中属性的内存地址拷贝到另一个字段。修改对象中的属性不会影响原数据，但是修改新对象中属性里面的内容，原对象也会受到影响

### 深拷贝及其实现方式

深拷贝会递归复制引用对象。最终一个对象属性修改不会影响另一个通过深拷贝生成的对象。

**深拷贝的实现方式：**

1. 手动创建对象并赋值
2. 实现 Cloneable 接口，重写 Object.clone() 方法。（clone 方法默认是浅拷贝，需要自己重写。不继承 Cloneable 接口，直接实现 clone 方法，调用时会报错）
3. 通过序列化和反序列化实现深拷贝

# 新特性

## java8 的时间和日期对象 

参考：https://blog.csdn.net/lemon_TT/article/details/109145432

**`LocalDate`、`LocalTime`、`LocalDateTime`、`Instant`为不可变对象**，都是 `final` 修饰，修改这些对象对象会**返回一个副本**，==线程安全。==

支持时区操作，操作实用，简单

### LocalDate

获取日期：年、月、日

```java
// 获取当前年月日  
LocalDate localDate = LocalDate.now();  
// 构造指定的年月日  
LocalDate localDate1 = LocalDate.of(2020, 10, 10); 

// 通过 getYear(),getMonth(),getDayOfMonth(),getDayOfWeek() 方法分别获取 年、月、日、星期几
```

### LocalTime

获取时间：时、分、秒

```java
// 获取当前时间
LocalTime localTime = LocalTime.of(13, 51, 10);  
// 构造指定的时间
LocalTime localTime1 = LocalTime.now();  

// 通过 getHour(),getMinute(),getSecond()  方法分别获取 时、分、秒
```

### LocalDateTime

获取日期和时间：年、月、日、时、分、秒

```java
// 通过各种方式构建 LocalDateTime 对象
LocalDateTime localDateTime = LocalDateTime.now();  
LocalDateTime localDateTime1 = LocalDateTime.of(2020, Month.SEPTEMBER, 10, 14, 46, 56);  
LocalDateTime localDateTime2 = LocalDateTime.of(localDate, localTime);  
LocalDateTime localDateTime3 = localDate.atTime(localTime);  
LocalDateTime localDateTime4 = localTime.atDate(localDate);  

// 通过 LocalDateTime 获取 LocalDate
LocalDatelocalDate = localDateTime.toLocalDate();  
// 通过 LocalDateTime 获取 LocalDate
LocalTime localTime = localDateTime.toLocalTime();  
```

### Instant（时间戳）

```java
// 获取当前时间戳
Instant instant = Instant.now();  

// 获取秒数
long currentSecond = instant.getEpochSecond();
// 获取毫秒数
long currentMilli = instant.toEpochMilli();  
```

## Java8 新特性 Stream 流

参考：https://blog.csdn.net/qq_36551991/article/details/108172160

Stream 是 Java 8 提供的新功能，是对集合 `Collection` 对象功能的增强，其本身并不存储任何 元素（或其地址值），与Lambda 表达式结合，也可以提高编程效率、简洁性和程序可读性。

同时它提供`串行`和`并行`两种模式进行汇聚操作，并行模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。 

### Stream流式思想

> 注意：Stream和IO流没有任何关系，**Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。**

Stream流式思想类似于工厂车间的 “生产流水线”，**Stream流不是一种数据结构，不保存数据**，而是对数据进行加工处理。Stream可以看做是流水线的一个工序。在流水线上，通过多个工序让原材料加工成一个商品。

<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/c13a4ebad535d1ed1a4eec104c88dde5919cb932.png@942w_471h_progressive-16544003188361.webp" alt="img" style="zoom: 67%;" />

### 通过 Stream 流，输出集合中以 `灵` 结尾，并且长度为 2 的元素

```java
public class StreamFlow {
    public static void main(String[] args) {
        List<String> list = Arrays.asList("寻血猎犬","直布罗陀","班加罗尔","命脉","恶灵","x亡灵","精灵");

        list.stream().filter( name -> name.endsWith("灵")).filter( name -> name.length() == 2).forEach(System.out::println);
    }
}
```

### 流的获取方式

通过 Collection 系列提供的 stream()（串行） 或 parallelStream()（并行）获取

java.util.collection 接口中加入了 default 方法 stream 和 parallelStream，也就是说 Collection 接口下的所有实现类都可以通过这两个方法来获取 Stream 流。

```java
list.stream();  // 串行
list.parallelStream();  // 并行
```

map 集合可以通过先获取 key 或者 value 的 set 集合，然后在通过这个集合获取到 stream 流 

```java
map.keySet().stream().forEach(System.out::println);
```

数组可以通过 Stream 类提供的 of() 方法进行流的获取

```java
Integer[] arr = {2,5,7,3,98,5,3,2,6,8,11};
Stream.of(arr).filter( num -> num > 10).forEach(System.out::println);
```

### 常用方法

| 方法名   | 方法作用   | <font color=red>返回值类型</font> | 方法类型 |
| -------- | ---------- | --------------------------------- | -------- |
| count    | 统计个数   | long                              | 终结方法 |
| forEach  | 逐个处理   | void                              | 终结方法 |
| filter   | 过滤       | Stream                            | 函数拼接 |
| limit    | 取用前几个 | Stream                            | 函数拼接 |
| skip     | 跳过前几个 | Stream                            | 函数拼接 |
| map      | 映射       | Stream                            | 函数拼接 |
| concat   | 组合       | Stream                            | 函数拼接 |
| sorted   | 排序       | Stream                            | 函数拼接 |
| distinct | 去重       | Stream                            | 函数拼接 |

**终结方法：** 返回值类型不再是Stream 类型的方法，不再支持链式调用。

**非终结方法： ** 返回值类型仍然是Stream类型的方法，支持链式调用。

> 注意：
>
> Stream只能操作一次
>
> Stream方法返回的是新的流
>
> **Stream不调用终结方法，中间的操作不会执行**

#### reduce()：归纳数据

```java
Integer reduce = Stream.of(arr).reduce(0, (sum, num) -> sum + num);
0：初始值
sum：每次返回的值会在下次传递给 sum
num：每次取出的值
```

#### map

将原来流中的数据进行统一的改变，例如下面将原来数组中的数据都加一

```java
Integer[] arr = {2,5,7,3,98,5,3,2,6,8,11};
Arrays.stream(arr).map(num -> num+1).forEach(System.out::println);
```

将原来stream流中的字符串全部变成大写

```java
ArrayList<String> strings = new ArrayList<>();
strings.add("a");
strings.add("b");
strings.add("c");
strings.add("d");
strings.add("e");
strings.stream().map(String::toUpperCase).forEach(System.out::println);
```





![image-20220801162926516](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220801162926516.png)

> 在实际开发过程中经常会将 map 和 reduce 一起使用
>
> 例如：计算 `a` 在集合中出现的次数
>
> ```java
> ArrayList<String> strings = new ArrayList<>();
> strings.add("a");
> strings.add("b");
> strings.add("c");
> strings.add("d");
> strings.add("a");
> strings.add("e");
> strings.add("a");
> Integer reduce = strings.stream().map(str -> "a".equals(str) ? 1 : 0).reduce(0, (sum, num) -> sum + num);
> System.out.println(reduce);
> ```

#### concat

将两个流合并成为一个流，使用 Stream 的静态方法 concat

```java
Stream<String> stream1 = Stream.of("a", "b", "c");
Stream<String> stream2 = Stream.of("e", "f", "g");
Stream.concat(stream1,stream2).forEach(System.out::println); // a b c e f g
```

### 结果收集

Stream 流通过 `collect 方法` 将结果收集到指定集合，两个流如下

```java
Stream<String> stream1 = Stream.of("a", "b", "c");
Stream<String> stream2 = Stream.of("e", "f", "g");
```

使用 collect 方法将其收集好不同类型的集合中代码如下

```java
List<String> list = Stream.concat(stream1, stream2).collect(Collectors.toList());
Set<String> set = Stream.concat(stream1, stream2).collect(Collectors.toSet());
Map<String, String> collect = Stream.concat(stream1, stream2).collect(Collectors.toMap(str -> str+"aaaa", str -> str));
```

使用 collect 方法将其收集到指定集合中，代码如下

```java
ArrayList<String> collect1 = Stream.concat(stream1,stream2).collect(Collectors.toCollection(ArrayList::new));
HashSet<String> collect2 = Stream.concat(stream1, stream2).collect(Collectors.toCollection(HashSet::new));
```

使用 toArray 方法将结果收集到数组

```java
Object[] collect1 = Stream.concat(stream1, stream2).toArray();
String[] strings = Stream.concat(stream1, stream2).toArray(String[]::new);
```

### 聚合运算

得到年龄最大的对象

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 88));
// 统计最大值：方法一
Optional<User> collect = userStream.max(Comparator.comparing(User::getAge));
// 统计最大值：方法二
Optional<User> collect = userStream.collect(Collectors.maxBy((a, b) -> a.getAge() - b.getAge()));
```

得到对象的年龄之和

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 88));
// 得到年龄之和：方法一
Integer collect = userStream.collect(Collectors.summingInt(w -> w.getAge()));
// 得到年龄之和：方法二
Integer collect = userStream.collect(Collectors.summingInt(User::getAge));
// 得到年龄之和：方法三
Integer collect = userStream.mapToInt(User::getAge).sum();
```

得到对象年龄平均值

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 88));
// 得到年龄平均值：方法一
Double collect = userStream.collect(Collectors.averagingDouble(value -> value.getAge()));
// 得到年龄平均值：方法二
Double collect = userStream.collect(Collectors.averagingDouble(User::getAge));
```

统计数量

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 34));
// 统计数量：方法一
Long collect = userStream.count();
// 统计数量：方法二
Long collect = userStream.collect(Collectors.counting());
```

### 分组操作

分组一次

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 34));
Map<String, List<User>> collect = userStream.collect(Collectors.groupingBy(User::getName));
Map<String, List<User>> collect = userStream.collect(Collectors.groupingBy(age -> age.getAge() >= 18 ? "成年人" : "未成年人"));
```

多级分组

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 34), new User("xxy", 34));
Map<String, Map<Object, List<User>>> collect = userStream.collect(Collectors.groupingBy(User::getName, Collectors.groupingBy(age -> age.getAge() >= 18 ? "成年人" : "未成年人")));
System.out.println(collect);
// {yyb={成年人=[com.zym.entity.User@66a29884]},
// xxy={成年人=[com.zym.entity.User@4769b07b], 未成年人=[com.zym.entity.User@cc34f4d]}, 
// zym={未成年人=[com.zym.entity.User@17a7cec2]}}
```

### 分区操作

`Collectors.partitioningBy()` 会根据值是否为 True，把集合中的数据分割为两个列表，一个 true 列表，一个 false 列表

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 13), new User("xxy", 34));
Map<Boolean, List<User>> collect = userStream.collect(Collectors.partitioningBy(user -> user.getAge() >= 18));
System.out.println(collect);
// {
// false=[com.zym.entity.User@66a29884, com.zym.entity.User@4769b07b],
// true=[com.zym.entity.User@cc34f4d, com.zym.entity.User@17a7cec2]
// }
```

### 拼接操作

`Collectors.joining()` 会根据指定的连接符

将所有元素连接成一个字符串，将用户名使用 `“,”` 分隔，拼接成字符串，代码如下：

```java
Stream<User> userStream = Stream.of(new User("zym", 15), new User("yyb", 22), new User("xxy", 13), new User("xxy", 34));
String collect = userStream.map(User::getName).collect(Collectors.joining(","));
System.out.println(collect);
```

### 并行流

并行流通过默认的 ForkJoinPool，可以提高多线程任务的速度。并行流可以通过下面的两种方式进行获取

> 通过List接口中的`parallelStream`方法获取

```java
List<Integer> list = new ArrayList<>();
Stream<Integer> integerStream = list.parallelStream();
```

> 通过已有的串行流转换为并行流`parallel`

```java
Stream<Integer> parallel = Stream.of(1, 2, 3).parallel();
```

### 解决并行流的线程安全问题

**同步锁**

```java
List<Integer> listNew = new ArrayList<>();
IntStream.rangeClosed(1,1000) // 生成数据1-1000
    .parallel()
    .forEach(i -> {
        synchronized (listNew){
            listNew.add(i);
        }
    });
System.out.println(listNew.size());
```

**线程安全容器**

```java
// Vector也可以使用但是已经过时
CopyOnWriteArrayList<Integer> listNew = new CopyOnWriteArrayList<>();
IntStream.rangeClosed(1,1000) // 生成数据1-1000
    .parallel()
    .forEach(i -> {
        listNew.add(i);
    });
```

**通过Stream中的toArray/collect（线程安全 可以查看文档注释）操作**

```java
List<Integer> listNew = new ArrayList<>();
List<Integer> list = IntStream.rangeClosed(1, 1000) // 生成数据1-1000
    .parallel()
    .boxed()// 返回由该流的元素组成的Stream ，每个元素都装箱为Integer
    .collect(Collectors.toList());
```

# Spring

## Spring 是什么？

Spring 是轻量的 java 企业级应用的开源开发框架

Spring 框架的核心功能可以应用在任何 Java 应用程序中

Spring 框架目标是简化 Java 企业级应用开发，并通过 POJO 为基础的编程模型促进良好的编程习惯。

核心：控制反转、面向切面编程

**控制反转（IOC）：**解决对象之间的耦合问题，参考 https://blog.csdn.net/bestone0213/article/details/47424255

​	<font color=red>控制：</font>打破传统模式中通过 new 关键字创建对象的方式，将对象的创建交给 ioc 容器控制

​	<font color=red>反转：</font>我们自己主动获取依赖对象的方式反转成了由容器帮助我们查找和注入依赖

​	Spring 使用控制反转技术实现了松耦合。依赖被注入到对象，而不是创建或寻找依赖对象。

**面向切面编程(AOP)：**前置通知，后置通知，环绕通知，异常通知，最终通知

​	Spring 支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。

​	在不修改目标方法的情况下，可以在方法执行前、执行后、返回值后、异常后要完成的操作

**依赖注入（DI）：**向容器中的一个对象提供它所需要使用的其他对象

**容器：**就是 ioc，Spring 包含并管理应用程序对象的配置及生命周期。

**事务管理：**Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA）。

**全局异常处理：**Spring 提供方便的 API 把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的 unchecked 异常。

## 有哪些不同类型的IOC（依赖注入）方式

构造注入：需要有有参构造

```xml
<bean id="user02" class="entity.User">
    <constructor-arg name="name" value="xxy"/>
</bean>
```

setter 注入：需要有 setter 方法

```xml
<bean id="user" class="entity.User">
    <property name="name" value="yyb" />
</bean>
```

引用类型自动注入：需要有 setter 方法，其实就是 setter 注入

```xml
<bean id="school" class="entity.School"></bean>
<bean id="user03" class="entity.User" autowire="byType">
    <property name="name" value="yyb03"/>
    <!-- <property name="school" ref="school"/>-->
</bean>
```

依赖注入的注解：`@Autowired，@Resource，@Inject`，可以放在 `setter` 方法，构造方法，属性上面

@Inject 的使用参考 [基于注解的构造注入](#基于注解的构造注入)

## 推荐哪种注入方式

构造注入和 `setter` 注入都可以使用，我们可以根据不同的情况选择不同的注入方式：

​	构造注入可以让依赖不可变，在没有 setter 方法的情况下构造注入的值无法更改

​	当属性不必须的时候，使用 setter 注入就更加灵活，并且该属性可以在以后重新配置或修改

不推荐直接将依赖注入注解写到属性上：

​	如果使用属性注入，该对象中的这个属性就只能在 spring 的 ioc 容器中使用，容器之外的地方无法为这个属性赋值（除非用反射）

## Bean 的作用域

作用域限定了 Spring Bean 的作用范围，在 Spring 配置文件定义 Bean 时，通过声明 `scope` 配置项，可以灵活定义 Bean 的作用范围

```xml
<bean id="user" class="entity.User" scope="singleton">
	<property name="name" value="yyb" />
</bean>
```

scope 配置项有 5 个属性，用于描述==五种作用域。==

- **singleton：**单例模式（默认值）无状态的 bean 使用这个

    使用该属性定义 Bean 时，<font color=red>IOC 容器仅创建一个 Bean 实例</font>，IOC 容器每次返回的是同一个 Bean 实例。

- **prototype：**有状态的 bean 使用这个

    使用该属性定义 Bean 时，IOC 容器可以创建多个 Bean 实例，<font color=red>每次返回的都是一个新的实例</font>。

- **request**

    该属性仅对 HTTP 请求产生作用，使用该属性定义 Bean 时，<font color=red>每次 HTTP 请求都会创建一个新的 Bean</font>，适用于 WebApplicationContext 环境。

- **session**

    该属性仅用于 HTTP Session，同一个 Session 共享一个 Bean 实例。<font color=red>不同 Session 使用不同的实例</font>，适用于 WebApplicationContext 环境。

- **global-session**

    该属性仅用于 HTTP Session，同 session 作用域不同的是，<font color=red>所有的 Session 共享一个 Bean 实例</font>，适用于 WebApplicationContext 环境。

## spring 中 bean 的生命周期。

参考：

​	https://www.cnblogs.com/javazhiyin/p/10905294.html

​	https://segmentfault.com/a/1190000040365130

bean 就是 java 对象，在 spring 中，由 ioc 容器进行实例化，组装和管理的对象

普通 java 对象由我们自己通过 new 关键字创建后就可以使用了，该对象不在使用后会由 jvm 自动进行垃圾回收

spring 中的 bean 的生命周期完全由容器控制，不需要我们通过 new 关键字进行创建，而是由 IOC 容器帮我们管理它，需要使用时直接从 IOC 容器中取即可。解决了对象之间的耦合问题

spring bean 的生命周期一般是说作用域为 singleton 的 bean 的生命周期，对于作用域为 prototype 的 bean，spring 在创建好后交给其使用者就不会再管理器后续的生命周期

bean 标签有两个重要的属性（init-method 和 destroy-method）。用它们你可以自己定制初始化和注销方法。它们也有相应的注解（@PostConstruct和 @PreDestroy）。

### bean 的生命周期主要有四个步骤：

![image-20220704142158574](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220704142158574.png)

**实例化：**Spring 启动，查找并加载需要被 Spring 管理的 bean，通过其构造方法进行 Bean 的实例化

**属性赋值：**Bean 实例化后对将 Bean 的引入和值注入到 Bean 的属性中

**初始化：**

初始化过程中有一些可以实现的扩展接口，如果有是实现扩展接口，则会执行接口对应的重写方法，一般情况下有如下接口，执行顺序如下

```
执行了User的构造方法
执行了setName方法
执行了setSchool方法
执行了 BeanNameAware 接口的 setBeanName() 方法
执行了 BeanFactoryAware 接口的 setBeanFactory() 方法
执行了 ApplicationContextAware 接口的 setApplicationContext() 方法
执行了自定义初始化 init() 方法
执行了 InitializingBean 接口的 afterPropertiesSet() 方法
```

**销毁：**

在 ioc 容器销毁时，容器中的 bean 也会随之销毁，销毁之前会执行对应的销毁方法

```
执行了自定义销毁 MyDestroy() 方法
执行了 DisposableBean 接口的 destroy() 方法
```

### bean 的生产周期中的扩展点及其作用

**Aware 接口：**为了获取 spring 容器中的资源

若 Spring 检测到 bean 实现了 Aware 接口，则会为其注入相应的依赖。所以**通过让bean 实现 Aware 接口，则能在 bean 中获得相应的 Spring 容器资源**

> Spring 中提供的 Aware 接口有：
>
> 1. BeanNameAware：注入当前 bean 对应 beanName；
> 2. BeanClassLoaderAware：注入加载当前 bean 的 ClassLoader；
> 3. BeanFactoryAware：注入 当前BeanFactory容器 的引用。
>
> 
>
> 以上是针对 BeanFactory 类型的容器，而对于 ApplicationContext 类型的容器，也提供了 Aware 接口，只不过这些 Aware 接口的注入实现，是通过 BeanPostProcessor 的方式注入的，但其作用仍是注入依赖。
>
> 1. EnvironmentAware：注入 Enviroment，一般用于获取配置属性；
> 2. EmbeddedValueResolverAware：注入 EmbeddedValueResolver（Spring EL解析器），一般用于参数解析；
> 3. ApplicationContextAware（ResourceLoader、ApplicationEventPublisherAware、MessageSourceAware）：注入 ApplicationContext 容器本身。

**BeanPostProcessor 接口:**

BeanPostProcessor 是 Spring 为**修改 bean**提供的强大扩展点，其可作用于容器中所有 bean

常用场景有：

1. 对于标记接口的实现类，进行自定义处理。例如3.1节中所说的ApplicationContextAwareProcessor，为其注入相应依赖；再举个例子，自定义对实现解密接口的类，将对其属性进行解密处理；
2. 为当前对象提供代理实现。例如 Spring AOP 功能，生成对象的代理类，然后返回。

**InitializingBean 和 init-method：**

InitializingBean 和 init-method 是 Spring 为 **bean 初始化** 提供的扩展点。

## spring用什么当做容器？

BeanFactory（hashmap）

## springMVC 表单验证

JSR 303 数据校验，使用第三方校验包 hibernate-validator

## 基于注解的构造注入

`@Inject` 要导入 `javax.inject-1.jar` 依赖，`@Autowired，@Resource` 也可以放到有参构造方法上

```java
@Service
public class UserService extends BaseService<User> {
    UserDao userDao;
    
    @Inject
    public UserService(UserDao userDao) {
        this.userDao=userDao;
    }
    
    public void save(String username, String password){
        userDao.save();
    }
}
```
## dom4j

Document for Java，java 解析 XML 的工具

## :yellow_heart:断言+@controllerAdvise

## :yellow_heart:成员变量，阻塞

## 两种切面的实现

### AspectJ：
​	**使用接口的方式生成代理对象**

​		Aspectj 是在编译的时候就植入代码到 class 文件，由于是静态织入的，所以性能相对来说比较好

​		Aspectj 不受类的特殊限制，不管方法是 private、或者 static、或者 final 的,都可以代理

​		Aspectj 不会代理除了限定方法之外任何其他诸如 toString()，clone() 等方法

### CGLIB：
​	**使用继承的方式生成代理对象**

​		可以为没有实现接口的类进行动态代理

​		static 方法，private 方法，final 方法等描述的方法是不能被代理的

​		CGLIB 会默认代理 Object 中 finalize，equals，toString，hashCode，clone等方法。比 JDK 代理多了 finalize 和 clone 

### spring 中的切面：

​	**<font color=red>Spring代理实际上是对 JDK 代理和 CGLIB 代理做了一层封装，同时引入了 AspectJ 中的一些注解</font>**

​	我们在使用 Spring AOP 的时候通常会在XML配置文件中设置 `<aop:aspectj-autoproxy proxy-target-class="true">` 来使用 `CGlib` 代理，但是，如果我们切入的对象实现了接口，不管这个属性是否为 true，spring 还是会使用 JDK 代理来实现切面。

## 拦截器

### 拦截器有三个方法
​	preHandle：在目标方法执行前执行，可以进行一些登录验证，返回值如果为 false ，则后面除了 afterCompletion  的所有方法都不会执行，包括目标方法

​	postHandle：在目标方法执行后执行

​	afterCompletion：在页面进行渲染后执行，可以用来释放内存等

### 执行顺序：

​	按照配置的先后，执行所有拦截器的 preHandle 方法

​	执行目标方法

​	按照配置相反的顺序，执行 postHandle 方法

​	按照配置相反的顺序，执行 afterCompletion 方法

## 拦截器和过滤器的对比

> 拦截器是基于 java 的反射机制的，而过滤器是基于函数回调。拦截器不依赖与 servlet 容器，过滤器依赖与 servlet 容器。
>
> 拦截器只能对 action 请求起作用，而过滤器则可以对几乎所有的请求起作用。
>
> 拦截器可以访问 action 上下文、值栈里的对象，而过滤器不能访问。
>
> 在 action 的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次
>
> 拦截器可以获取 IOC 容器中的各个 bean，而过滤器就不行，这点很重要，在拦截器里注入一个 service，可以调用业务逻辑。

拦截器和过滤器一起执行时，先执行过滤器，在执行中央调度器，最后执行拦截器，在执行 controller 方法

| 拦截器 | 过滤器 |
| --- | --- |
| 拦截器是springmvc中的对象 | 过滤器是 servlet 中的对象 |
| 拦截器是框架容器创建的 | 过滤器对象是 tomcat 创建的 |
| 拦截器是侧重对请求做验证处理的，可以截断请求 | 过滤器是侧重对 request，response 对象属性，参数设置值的，例如字符过滤器 |
| 拦截执行时间有三个 | 过滤器在请求之前执行 |
| 拦截器是拦截对 controller 动态资源的请求 | 过滤器可以过滤所有请求（动态和静态） |

## springmvc 和 servlet 的区别

servlet 的每个请求都需要在 wem.xml 中去配置，写一个 servlet 类，导致我们需要些很多的 Servlet ，但是基本上只需要实现 doGET\doPOST 两个方法，浪费资源

前端控制器本质就是一个Servlet，他是对 Servlet 的封装，封装的过程中，帮我们完成了对 init、他的父类是 FrameworkServlet 

<div align=center>
    <img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/1647405984657-32ea1b9c-9826-4c09-ae6f-b41d70ed9405.png"/>
</div>

FrameworkServlet 中会实现 Servlet 的 init 方法，初始化 spring 的子容器

### 线程安全问题：
​	springMVC 的 Controller 是单例的，每次请求都是同一个对象，如果在 Controller 中定义了类变量，在个变量是全局共享的，可能会造成多个变量修改他的值，出现与预期结果不符的现象，
### 解决方法：
​	尽量不要使用静态变量

​	使用 ThreadLocal 保存静态变量，将类变量保存在线程的变量域中，让不同的请求隔离开来

### <font color=red>父子容器：</font>

​	父容器就是 ioc 容器，启动 toncat 就会被 web.xml 中的那个监听器监听到，立马就会创建 ioc 容器，里面放的是service，dao，以及其他的各种bean；

​	子容器是 springmvc 的容器，里里面放着 web 层的所有组件，处理器映射器，处理器适配器，视图解析器， controller 等；

​	父容器会先创建（tomcat启动时)，子容器后创建，父容器的引用会保存在子容器中，可以通过子容器获取父容器的实例，然后获取其中的 bean。

​	spring 和 springmvc 整合时如果将 Controller 层的注解扫描器配置到了 spring 的配置文件中，将出现无法获取到对应请求路径。

​	如果将其它层的注解扫描配置到了 springmvc 的配置文件中，那么一些 spring 中一些功能将会失效，例如：事务

## Spring 事务失效的原因

其实发生最多就是自身调用、try catch 代码块影响事务执行、异常类型错误这三个了。

### 数据库不支持事务

以 MySQL 为例，MyISAM 引擎是不支持事务操作的，InnoBD 引擎在 MySQL 5.5.5 开始才是 MySQL 数据库的默认引擎，所以 MySQL 5.5.5 以前默认是不支持事务的

### 使用事务的方法没有被 ioc 管理

使用事务的类必须由 ioc 管理，不由 ioc 管理的类中，无法使用 spring 事务

例如 updateOrder 方法，在 @Service 注解被删除之后，事务不会生效

```java
@Service
public class OrderServiceImpl implements OrderService {

    @Transactional
    public void updateOrder(Order order) {
        // TODO
    }
}
```

### 方法访问权限不是 public

`@Transactional` 默认只能使用在 public 修饰的方法上，如果非要加在非 public 方法，则需要将开启 Aspectj 动态代理

### <font color=red>自身调用问题</font>

在一个类的方法中，间接调用的这个类中的其他方法，间接调用的这个方法的事务不会生效

如下，事务一和事务三不生效

```java
@Service
public class OrderServiceImpl implements OrderService {

    public void update(Order order) {updateOrder(order);}

    @Transactional	// 事务一
    public void updateOrder(Order order) {
        // TODO
    }
}
```

```java
@Service
public class OrderServiceImpl implements OrderService {

    @Transactional	// 事务二
    public void update(Order order) {updateOrder(order);}

    @Transactional	// 事务三
    public void updateOrder(Order order) {
        // TODO
    }
}
```

### 数据源没有配置事务管理器

### 事务的传播行为设置为 NOT_SUPPORTED

NOT_SUPPORTED 传播行为表示以非事务方式运行，如果之前有事务都会被挂起

### <font color=red>try catch 代码块影响事务执行</font>

我们将异常用 try catch 代码块包裹后，如果进行了异常处理，则事务不会生效

### <font color=red>异常类型错误</font>

在开发中，如果我们设置的 `rollbackFor` 为 `RuntimeException`，那么，抛出非运行时异常就不会回滚事务，所以我们必要时需要指定 `@Transactional(rollbackFor = Exception.class)`

## :yellow_heart:Spring 解决循环依赖



# MyBatis

## MyBatis 缓存机制

参考：https://tech.meituan.com/2018/01/19/mybatis-cache.html

### 一级缓存

mybatis 中提供了两级缓存，一级缓存是 SqlSession 级别的，在一次会话中，执行条件完全相同的 Sql，就会优先命中一级缓存，提高性能。

<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220714112006349.png" alt="image-20220714112006349"  />

> 每个 SqlSession 中持有了 Executor，每个 Executor 中有一个 LocalCache
>
> 当用户发起请求时，MyBatis 会根据当前的 SQL 语句生成一个 MappedStatement 在 LocalCache 中进行查询，如果查到了，直接返回，否则查数据库，然后将结果写入 LocalCache ，最后返回给用户
>
> <font color=red>注意：</font>一级缓存默认开启，无法关闭，可以设置 SESSION（在每一次sqlsession使用缓存） 或者 STATEMENT（只在语句执行时使用缓存） 级别

#### <font color=red>源码分析:</font>

**SqlSession**： 对外提供了用户和数据库之间交互需要的所有方法，隐藏了底层的细节。默认实现类是`DefaultSqlSession`。

```java
public class DefaultSqlSession implements SqlSession {
  ···
  private final Executor executor;
  ···
  private <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler) {
    ···
      MappedStatement ms = configuration.getMappedStatement(statement);
      // 最底层是通过 Executor 直接操作数据库
      return executor.query(ms, wrapCollection(parameter), rowBounds, handler);
    ···
  }
}
```

**Executor**： `SqlSession` 向用户提供操作数据库的方法，但和数据库操作有关的职责都会委托给 Executor。（分析其 `BaseExecutor` 实现类）

```java
public abstract class BaseExecutor implements Executor {
  ···
  protected PerpetualCache localCache;
  ···
  @Override
  public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
    List<E> list;
    ···
      // 在查询数据时，先查一遍 localCache 缓存
      list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;
      if (list != null) {
        // 处理参数
        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
      } else {
        // 缓存中没有就从数据库查询，这一步查询到数据后会直接存放进缓存中
        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
      }
    ···
      // 判断你配置的缓存级别，如果为 STATEMENT 就删除缓存
      if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
        // issue #482
        clearLocalCache();
      } 
    ···
    return list;
  }
   
  @Override
  public int update(MappedStatement ms, Object parameter) throws SQLException {
    ···
    // 清除一级缓存
    clearLocalCache();
    return doUpdate(ms, parameter);
  }
}
```

**Cache**： MyBatis中的Cache接口，提供了和缓存相关的最基本的操作。（上面用到的是其 `PerpetualCache` 实现类）

​	可以看到，一级缓存由一个 HashMap 实现，一级缓存的操作其实就是对 HashMap 的操作

```java
public class PerpetualCache implements Cache {
  private final String id;
  private final Map<Object, Object> cache = new HashMap<>();
  @Override
  public Object getObject(Object key) {
    return cache.get(key);
  }
```

<font color=red>注意：</font>在 SqlSession 中可以看到，不管是 insert 还是 delete 操作，都会走 update 流程，最终会调用 executor 的 update 方法，上面可以看到 executor 的 update 方法会直接清除一级缓存。

```java
  
  @Override
  public int insert(String statement, Object parameter) {return /** 走update **/update(statement, parameter);}

  @Override
  public int update(String statement) {return /** 走update **/update(statement, null);}

  @Override
  public int update(String statement, Object parameter) {
    try {
      dirty = true;
      MappedStatement ms = configuration.getMappedStatement(statement);
      return executor.update(ms, wrapCollection(parameter));
    } catch (Exception e) {
      throw ExceptionFactory.wrapException("Error updating database.  Cause: " + e, e);
    } finally {
      ErrorContext.instance().reset();
    }
  }

  @Override
  public int delete(String statement) {return /** 走update **/update(statement, null);}
```

### 二级缓存

二级缓存会造成数据脏读，基本无解，不推荐使用

在上文中提到的一级缓存中，其最大的共享范围就是一个 SqlSession 内部，如果多个 SqlSession 之间需要共享缓存，则需要使用到二级缓存。开启二级缓存后，SqlSessionFactory 在创建 SqlSession 时，会使用 CachingExecutor 装饰 Executor（`装饰者模式`），进入一级缓存的查询流程前，先在 CachingExecutor 进行二级缓存的查询，具体的工作流程如下所示。

![image-20220714145751737](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220714145751737.png)

二级缓存开启后，同一个 namespace 下有一个 Cache,他是一个全局变量，被多个 SqlSession 共享。

开启二级缓存后，数据的查询流程为：二级缓存 ——> 一级缓存 ——> 数据库

#### <font color=red>配置二级缓存：</font>

1. 需要在主配置文件中开启二级缓存：`<setting name="cacheEnabled" value="true"/>`

2. 在 mapper.xml 文件中通过 `<cache>` 标签，声明这个 `namespace` 使用二级缓存，并且可以自定义配置。

    `type`：cache使用的类型，默认是 `PerpetualCache`，这在一级缓存中提到过。

    `eviction`：定义回收的策略，常见的有FIFO，LRU。

    `flushInterval`：配置一定时间自动刷新缓存，单位是毫秒。

    `size`：最多缓存对象的个数。

    `readOnly`：是否只读，若配置可读写，则需要对应的实体类能够序列化。

    `blocking`：若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。

3. `<cache-ref namespace="">` 标签代表引用别的命名空间的 Cache 配置，两个命名空间的操作使用的是同一个 Cache。

    ```xml
    <cache-ref namespace="com.zym.dao.UserDao"/>
    ```

#### 二级缓存的问题

二级缓存是 namespace 级别的缓存，如果是多表关联查询的话，其他表进行了修改，不会影响到该表的二级缓存。会出现数据不一致（脏读）的问题。

insert、delete、update 操作会清空 namespace 下的所有缓存

> 如果有一个 UserMapper.xml 和一个 User_RoleMapper.xml
>
> 当我们通过 User_RoleMapper.xml 修改了一个用户的权限时，由于 UserMapper.xml 中的二级缓存不会改变，查出的错误数据就会危害很大

当然，你可以通过 `<cache-ref>` 将所有的缓存 namespace 指向同一个，但这里一旦出现增、删、改的操作就会清除所有缓存，粒度太大，没有意义。

#### 源码分析

CachingExecutor 就是 BaseExecutor 的一个装饰类

```java
public class CachingExecutor implements Executor {

  private final Executor delegate;
  private final TransactionalCacheManager tcm = new TransactionalCacheManager();
```

TransactionalCacheManager 就是一个缓存类，类似 Cache，它内部有一个 HashMap（transactionalCaches）存放缓存数据

> transactionalCaches 的结构为 {namespace名称：TransactionalCache}

```java
public class TransactionalCacheManager {
  private final Map<Cache, TransactionalCache> transactionalCaches = new HashMap<>();
```

TransactionalCache 也是一个缓存内，它他来存放不同名称空间中缓存的具体数据

```java
public class TransactionalCache implements Cache {

  private final Cache delegate;
  private boolean clearOnCommit;
  private final Map<Object, Object> entriesToAddOnCommit;
  private final Set<Object> entriesMissedInCache;
```

# Spring Boot

## Starter

Starter 可以理解成一个启动器，它包含了一系列集成到项目中的依赖，让我们在集成其他框架的时候做到开箱即用，极大简化了我们的配置，也不需要到处寻找依赖。

# tomcat

## tomcat8 nio 线程模型

![image-20220330132044449](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220330132044449.png)

请求的处理流程：

​	<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/10115652-9485e8190f5edfa4.jpg" alt="img" style="zoom:50%;" />

```
接收器（Acceptor）线程，用于接收连接，每个线程都有自己的选择器（Selector），Acceptor 只负责接收（accept）新的连接，一旦连接建立之后就将连接进行包装，放到 Poller 队列中

Poller 线程组，用于接收 socket 事件，当 socket 可读或可写时，将其包装，添加到 Worker 的线程队列中

worker 线程组。用于对请求进行处理，包括分析请求报文并创建 Request 对象，调用容器的 pipeline 进行处理。
```

阻塞：一个请求获取信息，没有获取到，就一直阻塞到这里，等待信息获取

非阻塞：一个请求获取信息，没有获取到，就返回一个特定值，等一会再来获取，直到获取成功

**<font color=red>bio：</font>**一个请求连接，就使用一个线程处理，没有中间的 Poller，直到请求完成，同时请求过多就会产生大量线程，随着开启的线程数目增多，将会消耗过多的内存资源，导致服务器变慢甚至崩溃

**<font color=red>nio：</font>**用专门的线程监听 IO 事件，他们有自己的 Selector ，一旦监听到有 io 读写，他不会自己处理，而是将其包装成一个 Runnable ，交给专门的 Worker 线程池处理，这种情况每个连接可能会被多个线程同时操作，相比第一种并发性提高了，但是也可能引来多线程问题。==NIO适合处理连接数目特别多，但是连接比较短==

Acceptor 中通过 accept 获取连接，当前连接数大于最大连接数后，就直接阻塞，一旦处理完成，连接数小于最大连接数后，就不在阻塞

线程池：最大线程默认 200，核心线程 10 个，满了就会放到工作线程的等待队列 （TaskQueue），队列满了就会创建非核心线程

## tomcat 的容器

​	tomcat 一共有四个容器，engin，host，context，warpper

​	他们是嵌套关系，每个容器里面都有一个 pipeline 对象，只要触发容器中 pipeline 的第一个 Valve ，那么这个容器中的所有 Vavle 都会依次执行， pipeline 的最后一个 Vavle 会调用下一层容器 pipeline 的第一个 Vavle

​	整个调用过程由连接器中的 Adapter 触发的，它会调用 Engine 的第一个 Valve

​	Wrapper 容器的最后一个 Valve 会创建一个 Filter 链，并调用 doFilter() 方法，最终会调到 Servlet 的 service 方法

<img src="https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/image-20220330134904969.png" alt="image-20220330134904969" style="zoom:67%;" />

​	**Engin ：**全局只有一个，负责<font color=red>根据域名</font>将请求路由到不同的 host 

​	**Host：**根据不同的请求根目录，将请求路由到 Context

​	**Context：**根据不同的 Servlet 请求地址，将请求路由到对应的 Warpper

​	**Warpper：**根据 Servlet 拦截路径，将请求交给对应的 Servlet 处理

# 数据库

## 事务

### 事务的特性：ACID

**原子性（Atomicity）**

​	原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。

**一致性（Consistency）**

​	事务前后数据的完整性必须保持一致。

**隔离性（Isolation）**

​	事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。

**持久性（Durability）**

​	持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响

### 出现的并发问题：

**脏读：**在一个事务中，读取到另一个事务还没有提交的数据，如果此时这个事务回滚，那么这个数据就是一个脏数据

**幻读：**在事务 A 中，将一些数据修改（例如删除某个表中的所有数据），同时，另一个事务 B 又把这些东西改回去。

​	这时，事务 A 重新查看这个表，发现刚刚删除所有数据的表中还有数据

**不可重复度：**当事务 A 查询一条数据，之后事务 B 对其进行了修改，当事务 A 再次查询这个数据时会发现和第一次查询到的数据不同

### 事务的隔离级别

**读未提交：**

​	没有解决任何并发问题，一个事务可以读取到另一个事务还未提交的数据

**读已提交：**

​	解决了脏读的问题，一个请求只能读取到另一个请求提交后的数据

​	但是还是会出现不可重复度和幻读的问题

**可重复度（ innoDB 默认隔离级别）：**

​	在一个事务中，第一次读取某个数据时会生成一个快照，之后再查询这个数据，就是直接从快照中取值，在这个事务中第一次读取到的是什么，之后读取到的就是什么

​	所以，不管其他的事务对这个数据进行了怎样的操作，他读取出来的依旧是第一次读取到的数据，就算其他事务将这条数据删除了他也能读取到。

​	但是，虽然查询出来的数据并没有改变，但是在进行其他操作的时候，会出现问题，例如，事务 A 查询 id 为 1001 的用户，没有查到，事务 B 之后往数据库中插入了 id 为 1001 的用户，这时，事务 A 想插入 id 为 1001 的用户，发现主键冲突插入失败，但是事务 A 还是查询不到 id 为 1001 的用户，A 提交了事务才能查询到此数据

​	可重复度解决了脏读和不可重复度的问题，但是仍然有幻读的问题存在

**串行化：不存在任何并发问题**

​	牺牲数据库的多线程多线程处理能力，当前事务执行完才能执行下一个事务，相当于加锁，禁止其他事务在本事务范围内的一切操作

​	它解决了全部的并发问题，但是并发性能极低，还可能会发生死锁的现象

### 事务的传播行为

事务的传播行为有七个值，一般使用红色的三种

| 事务传播行为类型                          | 说明                                                         |
| ----------------------------------------- | ------------------------------------------------------------ |
| <font color=red>REQUIRED</font>           | spring的默认传播行为，方法在调用时，如果已经存在一个事务中，就使用当前事务。如果当前没有事务，就新建一个事务，方法在新事务中运行 |
| <font color=red>SUPPORTS</font>           | 支持事务，如果当前方法有事务，就使用事务，没有事务，也能正常运行 |
| <font color=red>REQUIRES_NEW      </font> | 方法需要一个新事务，如果方法调用时，存在一个事务，则原来的事务暂停，直到新事物运行完成。如果方调用时，没有事务，则创建一个新事务，在新事务执行代码。新事务里的操作commit之后，原来事务回滚对新事务提交的操作没有影响 |
| NOT_SUPPORTED                             | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   |
| NEVER                                     | 以非事务方式执行，如果当前存在事务，则抛出异常。             |
| NESTED                                    | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 REQUIRED 类似的操作。 |
| MANDATORY                                 | 使用当前的事务，如果当前没有事务，就抛出异常。               |

## 间隙锁 

读已提交模式下，修改没有数据的间隙，会对这个间隙的所有数据加锁

![img](https://zym-notes.oss-cn-shenzhen.aliyuncs.com/img/1651811964602-3b0050a3-4827-4680-b787-d331353dc0fe.png)

一个事务修改 id = 6 的数据，就会对 (5,10) 进行加锁，这时，其他事务无法插入这个范围的数据，但是可以对其进行修改。

如果这时另一个事务修改 id = 8 的数据，他也会对 (5,10) 进行加锁，如果这时插入 id 在这个范围的数据，就会出现死锁的情况，两个事务都不能插入这个范围的数据。

参考：https://www.cnblogs.com/myf008/p/14588380.html

## 索引

是一种排好序的能够快速查找的数据结构，能够提高查找速度，但是会降低更新速度（更新的同时需要维护索引）。

它往往以文件的形式存储到磁盘上，通常是 B + 树

表中记录少，经常增删盖查的字段、where 条件中用不上的字段最好不要创建索引

**普通索引**

分为单行索引和复合索引

为单列或多列设置索引，`CREATE INDEX <索引的名字> ON 表名 (列的列表)`

**唯一索引**

唯一索引是不允许其中任何两行具有相同索引值的索引。`CREATE UNIQUE INDEX <索引的名字> ON 表名(列的列表)；`

**主键索引**

数据库会为表的主键自动创建主键索引

### 索引失效的情况

`create index in_a_b_c tablename (a,b,c)`

查询需要通过参数 a 索引才能生效，如果 a 和 c 之间，没有 b，那么只会有部分索引生效，a 生效，b 和 b 后面比分的索引不生效

索引列上有计算、函数、自动或手动的类型转换时，索引不生效

如果使用了范围查询（">","<","in","between"），则范围查询后面的索引不生效

“ != ” 和 "<>" 也会导致索引失效

字符串类型的数据不加单引号也会导致索引失效

模糊查询使用了 % 之后，后面的索引会失效，% 相当于范围查询，查询的数据使用具体的列名，不使用 * ，在索引的范围内可以使用索引，所以使用 % 模糊查询，最好只在右边写 %，不要使用 * 代替所有列：`select id,name from user where name like 'yyb%'`

or、is null、is not null 也会导致索引失效

## explain 性能分析

 Extra 字段中出现 Using filesort、Using temporary 需要格外注意，性能可能很差

### sql 优化问题

永远大表驱动小表

### order by 排序需要注意下面的问题

使用到了非索引字段排序，或者没有使用到索引的第一个列，索引列的顺序与排序时不同，会出现索引失效，产生Using filesort

排序使用到了索引第一列，但是 where 条件中有索引的其他列时，索引会失效

使用了索引中的两个字段排序，但是一个是升序、一个是降序（顺序相反）会导致索引失效

### group by 与 order by 相同，但是能在 where 中完成的条件就不要放到 having 中执行

# 分布式

## 如何实现分布式唯一 ID

在分布式场景下，保证我们每个服务生成的 id 都是唯一的，就显得尤为重要。

分布式 id 的主要特性：

- 全局唯一：必须保证生成的 ID 是全局性唯一的，这是分布式 ID 的基本要求；
- 有序性：生成的 ID 需要按照某种规则有序，便于数据库的写入和排序操作；
- 可用性：需要保证高并发下的可用性。除了对 ID 号码自身的要求，业务还对 ID 系统的可用性要求极高；
- 自主性：分布式环境下不依赖中心认证即可自行生成 ID；
- 安全性：不暴露系统和业务的信息。在一些业务场景下，会需要 ID 无规则或者不规则。

常用实现方式主要有：

1. UUID

    性能高，本地生成，没有网络消耗

    UUID 太长，不易存储，基于时间的 UUID 可能会造成机器 mac 地址泄漏

2. 数据库自增 id

    及其依赖数据库，生成效率取决于数据库的读写速度

3. Redis 通过 incr 和 incrby 的原子性生成自增生产 id

    效率非常高，弹药考虑 Redis 的持久化问题

    RDB 持久化，如果一下连续新增了几个 id 还没来得及进行持久化，这时，Redis 宕机后重启会出现重复ID

    AOF 持久化，相当于对每条数据进行持久化，如果宕机，不会出现重复 ID，但是如果数据量比较大，宕机后重启时间

4. 雪花算法

    稳定性高，生成的 id 趋势递减

    太过依赖机器的时间，分布式部署场景下单机递增，服务器时钟回拨可能会导致服务不可用

5. 数据库号段模式

    一次从数据库中获取多个 id 缓存到本地（例如：`(0,1000]`），用完后再去数据库中查询下一个号段的 id

6. 第三方解决方案

    美团 Leaf-segment

    滴滴 Tingid

    百度 UidGenerator

# 锁

